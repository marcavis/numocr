    A primeira consideração tomada na implementação do algoritmo foi decidir a
quantidade de neurônios na camada intermediária - a média geométrica pareceu ser
interessante para isso, mas, conforme o desenvolvimento prosseguiu, viu-se
que um número menor era suficiente.
    Uma preocupação inicial foi sempre evitar enganos nos índices; felizmente,
a sintaxe de Python é razoavelmente compacta, portanto é possível escrever
código que se pareça com as funções matemáticas descritas no algoritmo da
apostila, sem ser obscurecido por loops - até certo ponto, pois o preenchimento
de matrizes fica mais claro usando loops para uma das dimensões.
    Um problema encontrado, no momento em que o algoritmo chegou no cálculo de
z_in, foi que o valor que chegava para a função sigmoide era sempre muito alto,
na faixa de 30, o que sempre levava a um resultado muito próximo a 1. Tentou-se,
sem muita convicção, dividir os valores de z_in por algum fator, a título de
normalização, para que o resultado da função sigmoide se aproximasse de 0.5,
sendo portanto valores mais adequados para se trabalhar.
    Só no dia seguinte é notado que a função de geração de pesos aleatórios
estava gerando pesos apenas entre 0.0 e 1.0, o que explicava essa tendência
positiva exagerada.
    Os valores continuam muito altos, então tentaremos uma normalização das
entradas, para que valores de 0 a 255 fiquem compreendidos entre 0.0 e 1.0.
    Em algum ponto, uma preocupação com a velocidade do código aparece, então
testamos a função time.time() da biblioteca Python para verificar qual a parte
mais pesada do código.
    Processamento de uma linha: 28 ms, dos quais 8.8 ms são para atualizar os
pesos da primeira camada, e 0.2 ms para atualizar os pesos da segunda camada.
Talvez haja algo melhor que um loop?
    De fato, atualizar pesos linha por linha, usando list comprehensions, como:
    pesosV[i] = [x + y for (x,y) in zip(pesosV[i], delta_v[i])]
    Economiza 3 ms por linha processada.
    Porém, uma otimização bem mais potente seria diminuir a quantidade de
neurônios intermediários - uma diminuição em 50% diminui o tempo de
processamento por linha em cerca de 45%, e tendo uma piora apenas leve na
diminuição de erro médio por linha.
    Para testar o acerto do algoritmo, colocamos um limiar de 0.7 (seria
arrojado demais? Conservador demais? Há de se testar). Assim, se o resultado de
um dos itens da camada final for maior que o limiar, ele será convertido em uma
resposta positiva; para testar se a resposta foi correta, convertemos o vetor
da resposta em um vetor de booleanos (depois transformados em 0 e 1), e
verificamos se é completamente igual à resposta esperada; os erros possíveis
são: ausência de itens 1 na resposta, item 1 incorreto na resposta, e presença
de mais de um item 1 na resposta.
    Com o uso de algumas variáveis de depuração, encontramos os seguintes níveis
de acerto executando o treinamento com a base com 10 mil linhas,
rodando por 20 épocas, com limiar de 0.7, e tempo de processamento de 44 minutos:
    Epoca 1: 55.74 %  de acerto
    Epoca 2: 78.42 %  de acerto
    Epoca 3: 83.19 %  de acerto
    Epoca 4: 86.08 %  de acerto
    Epoca 5: 87.96 %  de acerto
    Epoca 6: 89.34 %  de acerto
    Epoca 7: 90.37 %  de acerto
    Epoca 8: 91.26 %  de acerto
    Epoca 9: 92.20 %  de acerto
    Epoca 10: 92.85 %  de acerto
    Epoca 11: 93.51 %  de acerto
    Epoca 12: 94.17 %  de acerto
    Epoca 13: 94.66 %  de acerto
    Epoca 14: 95.07 %  de acerto
    Epoca 15: 95.47 %  de acerto
    Epoca 16: 95.81 %  de acerto
    Epoca 17: 96.18 %  de acerto
    Epoca 18: 96.42 %  de acerto
    Epoca 19: 96.61 %  de acerto
    Epoca 20: 96.83 %  de acerto

    Porém, notamos que o desempenho no teste da base de 60.000 linhas,
posteriormente ao treinamento, não melhorou muito depois de 10 épocas, sugerindo
que a rede neural estava se encaminhando para um certo grau de overfitting.
    O programa teste.py é baseado no treinamento, porém simplificado para não
alterar pesos. Possui algumas métricas de avaliação da rede neural: quantidade
de acertos, quantidade de acertos por número esperado (achávamos que distinguir
1 de 7 seria difícil, mas percebeu-se que o número 5 era o mais difícil afinal),
e tipo de erro - se a rede não classificou como nenhum número, ou se classificou
como o número errado, ou se escolheu dois (ou mais) números ao mesmo tempo.
    Resultado da execução de teste.py usando a base de 60 mil linhas:

Tempo de processamento:  236.65 s
Acertos:  51601 / 59900
Taxa de acerto:  86.15 %
Acertos onde o número 0 era esperado: 5426 / 5913 ou 91.76 %
Acertos onde o número 1 era esperado: 6448 / 6732 ou 95.78 %
Acertos onde o número 2 era esperado: 5243 / 5949 ou 88.13 %
Acertos onde o número 3 era esperado: 5088 / 6120 ou 83.14 %
Acertos onde o número 4 era esperado: 4969 / 5833 ou 85.19 %
Acertos onde o número 5 era esperado: 3971 / 5412 ou 73.37 %
Acertos onde o número 6 era esperado: 5325 / 5908 ou 90.13 %
Acertos onde o número 7 era esperado: 5441 / 6256 ou 86.97 %
Acertos onde o número 8 era esperado: 4606 / 5839 ou 78.88 %
Acertos onde o número 9 era esperado: 5084 / 5939 ou 85.6 %
Erros onde o programa não classificou como nenhum número: 5928
Erros onde o programa classificou como o número errado: 1813
Erros onde o programa classificou como mais de um número ao mesmo tempo: 559

    Vemos que o fato de que o erro mais comum é a rede neural decidir não
apontar nenhum número como o correto; talvez então seja interessante reduzir o
limiar, atualmente em 0.7. Usando 0.5, há uma melhora razoável na taxa de
acerto:

Tempo de processamento:  251.9 s
Acertos:  52329 / 59900
Taxa de acerto:  87.36 %
Acertos onde o número 0 era esperado: 5483 / 5913 ou 92.73 %
Acertos onde o número 1 era esperado: 6465 / 6732 ou 96.03 %
Acertos onde o número 2 era esperado: 5243 / 5949 ou 88.13 %
Acertos onde o número 3 era esperado: 5117 / 6120 ou 83.61 %
Acertos onde o número 4 era esperado: 5120 / 5833 ou 87.78 %
Acertos onde o número 5 era esperado: 4071 / 5412 ou 75.22 %
Acertos onde o número 6 era esperado: 5371 / 5908 ou 90.91 %
Acertos onde o número 7 era esperado: 5552 / 6256 ou 88.75 %
Acertos onde o número 8 era esperado: 4711 / 5839 ou 80.68 %
Acertos onde o número 9 era esperado: 5196 / 5939 ou 87.49 %
Erros onde o programa não classificou como nenhum número: 3898
Erros onde o programa classificou como o número errado: 2245
Erros onde o programa classificou como mais de um número ao mesmo tempo: 1429
